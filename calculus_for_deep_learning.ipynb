{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qwertydgdhegncf/Deep-Learning-Fundamentals/blob/main/calculus_for_deep_learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üéì Summary: Calculus for Deep Learning\n",
        "\n",
        "Congratulations! You've learned the calculus that powers deep learning!\n",
        "\n",
        "### The Complete Training Loop\n",
        "\n",
        "```python\n",
        "for epoch in range(num_epochs):\n",
        "    # 1. Forward pass: compute predictions\n",
        "    predictions = model.forward(inputs)\n",
        "    \n",
        "    # 2. Compute loss: how wrong are we?\n",
        "    loss = loss_function(predictions, targets)\n",
        "    \n",
        "    # 3. Backward pass: compute gradients using CHAIN RULE\n",
        "    gradients = model.backward(loss)  # This is CALCULUS!\n",
        "    \n",
        "    # 4. Update weights: gradient descent\n",
        "    weights = weights - learning_rate * gradients\n",
        "```\n",
        "\n",
        "### Key Concepts\n",
        "\n",
        "| Concept | What It Does | Deep Learning Use |\n",
        "|---------|-------------|-------------------|\n",
        "| **Derivative** | Rate of change | Sensitivity of output to input |\n",
        "| **Chain Rule** | Compose derivatives | Backpropagation through layers |\n",
        "| **Gradient** | Vector of partials | Direction of steepest ascent |\n",
        "| **Gradient Descent** | Follow negative gradient | Minimize loss function |\n",
        "| **Backpropagation** | Efficient chain rule | Compute all gradients at once |\n",
        "\n",
        "### The Core Equations\n",
        "\n",
        "1. **Forward pass**: `z = Wx + b`, `a = activation(z)`\n",
        "2. **Loss**: `L = loss_fn(prediction, target)`\n",
        "3. **Backward pass**: `‚àÇL/‚àÇW = ‚àÇL/‚àÇa ¬∑ ‚àÇa/‚àÇz ¬∑ ‚àÇz/‚àÇW`\n",
        "4. **Update**: `W = W - Œ∑ ¬∑ ‚àÇL/‚àÇW`\n",
        "\n",
        "---\n",
        "*Created with ‚ù§Ô∏è for Introduction to Deep Neural Networks*"
      ],
      "metadata": {
        "id": "8kFrmNCxO0aK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "‚úÖ **Section 5 Complete!** You now understand:\n",
        "- How backpropagation uses the chain rule\n",
        "- Forward pass saves values, backward pass computes gradients\n",
        "- How a complete neural network learns\n",
        "\n",
        "Now let's summarize everything!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "E5Mp9B_OO0aM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Visualize training\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Loss curve\n",
        "axes[0].plot(losses, 'b-', linewidth=1)\n",
        "axes[0].set_xlabel('Epoch')\n",
        "axes[0].set_ylabel('Loss (MSE)')\n",
        "axes[0].set_title('Training Loss Over Time', fontweight='bold')\n",
        "axes[0].set_yscale('log')\n",
        "axes[0].grid(True, alpha=0.3)\n",
        "\n",
        "# Decision boundary\n",
        "xx, yy = np.meshgrid(np.linspace(-0.5, 1.5, 100), np.linspace(-0.5, 1.5, 100))\n",
        "grid = np.c_[xx.ravel(), yy.ravel()]\n",
        "Z = nn.forward(grid).reshape(xx.shape)\n",
        "\n",
        "axes[1].contourf(xx, yy, Z, levels=20, cmap='RdBu', alpha=0.7)\n",
        "axes[1].scatter(X[:, 0], X[:, 1], c=y.ravel(), cmap='RdBu', s=200, edgecolors='black', linewidth=2)\n",
        "axes[1].set_xlabel('x‚ÇÅ')\n",
        "axes[1].set_ylabel('x‚ÇÇ')\n",
        "axes[1].set_title('Learned Decision Boundary (XOR)', fontweight='bold')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üéâ Success! The network learned XOR through backpropagation!\")\n",
        "print(\"   Blue = 0, Red = 1. The curved boundary separates the XOR pattern.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "Ri3AvYNcO0aM",
        "outputId": "0220804a-a6c1-4c8d-fc0a-417a97f72b3a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-1128453474.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualize training\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Loss curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlosses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'b-'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlinewidth\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Complete Backpropagation Example: XOR Problem\n",
        "# Network: 2 inputs ‚Üí 2 hidden (sigmoid) ‚Üí 1 output (sigmoid)\n",
        "\n",
        "class SimpleNeuralNetwork:\n",
        "    def __init__(self):\n",
        "        # Xavier/He initialization\n",
        "        np.random.seed(42)\n",
        "        self.W1 = np.random.randn(2, 4) * 0.5  # 2 inputs ‚Üí 4 hidden\n",
        "        self.b1 = np.zeros((1, 4))\n",
        "        self.W2 = np.random.randn(4, 1) * 0.5  # 4 hidden ‚Üí 1 output\n",
        "        self.b2 = np.zeros((1, 1))\n",
        "\n",
        "    def sigmoid(self, z):\n",
        "        return 1 / (1 + np.exp(-np.clip(z, -500, 500)))\n",
        "\n",
        "    def sigmoid_derivative(self, a):\n",
        "        return a * (1 - a)\n",
        "\n",
        "    def forward(self, X):\n",
        "        \"\"\"Forward pass - save values for backprop\"\"\"\n",
        "        self.X = X\n",
        "        self.z1 = X @ self.W1 + self.b1\n",
        "        self.a1 = self.sigmoid(self.z1)\n",
        "        self.z2 = self.a1 @ self.W2 + self.b2\n",
        "        self.a2 = self.sigmoid(self.z2)\n",
        "        return self.a2\n",
        "\n",
        "    def backward(self, y_true, learning_rate=0.5):\n",
        "        \"\"\"Backward pass - compute gradients using chain rule\"\"\"\n",
        "        m = y_true.shape[0]  # batch size\n",
        "\n",
        "        # Output layer gradients (chain rule!)\n",
        "        dL_da2 = 2 * (self.a2 - y_true)  # MSE derivative\n",
        "        da2_dz2 = self.sigmoid_derivative(self.a2)\n",
        "        dz2 = dL_da2 * da2_dz2  # Element-wise for batch\n",
        "\n",
        "        dW2 = (self.a1.T @ dz2) / m\n",
        "        db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Hidden layer gradients (chain rule continues!)\n",
        "        da1 = dz2 @ self.W2.T\n",
        "        dz1 = da1 * self.sigmoid_derivative(self.a1)\n",
        "\n",
        "        dW1 = (self.X.T @ dz1) / m\n",
        "        db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
        "\n",
        "        # Update weights (gradient descent step)\n",
        "        self.W2 -= learning_rate * dW2\n",
        "        self.b2 -= learning_rate * db2\n",
        "        self.W1 -= learning_rate * dW1\n",
        "        self.b1 -= learning_rate * db1\n",
        "\n",
        "        return np.mean((self.a2 - y_true) ** 2)  # Return loss\n",
        "\n",
        "# XOR data\n",
        "X = np.array([[0, 0], [0, 1], [1, 0], [1, 1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n",
        "\n",
        "# Train!\n",
        "nn = SimpleNeuralNetwork()\n",
        "losses = []\n",
        "\n",
        "print(\"üß† Training Neural Network with Backpropagation\")\n",
        "print(\"=\"*50)\n",
        "print(\"Problem: XOR (not linearly separable!)\")\n",
        "print(f\"Architecture: 2 ‚Üí 4 ‚Üí 1\")\n",
        "\n",
        "for epoch in range(5000):\n",
        "    predictions = nn.forward(X)\n",
        "    loss = nn.backward(y, learning_rate=1.0)\n",
        "    losses.append(loss)\n",
        "\n",
        "    if epoch % 1000 == 0:\n",
        "        print(f\"Epoch {epoch}: Loss = {loss:.6f}\")\n",
        "\n",
        "print(f\"\\nFinal predictions:\")\n",
        "for xi, yi, pred in zip(X, y, predictions):\n",
        "    print(f\"  Input: {xi} ‚Üí Pred: {pred[0]:.3f} (Target: {yi[0]})\")"
      ],
      "metadata": {
        "id": "l68798AHO0aN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5Ô∏è‚É£ Backpropagation - The Heart of Deep Learning\n",
        "\n",
        "**Backpropagation** is just the **chain rule** applied efficiently to compute ALL gradients in a neural network.\n",
        "\n",
        "### The Key Insight\n",
        "\n",
        "Instead of computing gradients from scratch for each weight, we:\n",
        "1. **Forward pass**: Compute and SAVE all intermediate values\n",
        "2. **Backward pass**: Use chain rule from output to input, reusing saved values\n",
        "\n",
        "This reduces computation from O(n¬≤) to O(n) for n weights!"
      ],
      "metadata": {
        "id": "ec7AZEUvO0aN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "‚úÖ **Section 4 Complete!** You now understand:\n",
        "- Gradient descent algorithm\n",
        "- How weights are updated to minimize loss\n",
        "- The crucial role of learning rate\n",
        "\n",
        "Next: **Backpropagation** - efficient gradient computation!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "guy4E_LaO0aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Learning Rate Effects\n",
        "fig, axes = plt.subplots(1, 3, figsize=(15, 4))\n",
        "\n",
        "learning_rates = [0.01, 0.1, 0.5]\n",
        "titles = ['Too Small (lr=0.01)', 'Just Right (lr=0.1)', 'Too Large (lr=0.5)']\n",
        "\n",
        "for ax, lr, title in zip(axes, learning_rates, titles):\n",
        "    history = gradient_descent(loss, loss_gradient, [-1.5, 1.5], lr, 30)\n",
        "    weights_path = np.array([h[0] for h in history])\n",
        "\n",
        "    contour = ax.contour(W1, W2, L, levels=15, cmap='viridis', alpha=0.5)\n",
        "    ax.plot(weights_path[:, 0], weights_path[:, 1], 'ro-', markersize=4, linewidth=1)\n",
        "    ax.scatter([1], [-0.5], color='green', s=100, marker='*', zorder=5)\n",
        "    ax.set_xlabel('w‚ÇÅ')\n",
        "    ax.set_ylabel('w‚ÇÇ')\n",
        "    ax.set_title(title, fontweight='bold')\n",
        "    ax.set_xlim(-3, 4)\n",
        "    ax.set_ylim(-3, 3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üí° Learning Rate is CRITICAL:\")\n",
        "print(\"   ‚Ä¢ Too small ‚Üí Very slow convergence\")\n",
        "print(\"   ‚Ä¢ Just right ‚Üí Smooth, efficient convergence\")\n",
        "print(\"   ‚Ä¢ Too large ‚Üí Oscillation, may diverge!\")"
      ],
      "metadata": {
        "id": "i0ELQQHdO0aO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing the gradient descent path\n",
        "fig, axes = plt.subplots(1, 2, figsize=(14, 5))\n",
        "\n",
        "# Left: Path on contour plot\n",
        "ax1 = axes[0]\n",
        "contour = ax1.contour(W1, W2, L, levels=15, cmap='viridis')\n",
        "ax1.clabel(contour, inline=True, fontsize=8)\n",
        "\n",
        "# Plot path\n",
        "weights_path = np.array([h[0] for h in history])\n",
        "ax1.plot(weights_path[:, 0], weights_path[:, 1], 'ro-', markersize=4, linewidth=1, label='GD path')\n",
        "ax1.scatter([initial[0]], [initial[1]], color='red', s=150, marker='o', zorder=5, label='Start')\n",
        "ax1.scatter([1], [-0.5], color='green', s=150, marker='*', zorder=5, label='Minimum')\n",
        "\n",
        "ax1.set_xlabel('w‚ÇÅ')\n",
        "ax1.set_ylabel('w‚ÇÇ')\n",
        "ax1.set_title('Gradient Descent Path', fontweight='bold')\n",
        "ax1.legend()\n",
        "\n",
        "# Right: Loss over time\n",
        "ax2 = axes[1]\n",
        "losses = [h[1] for h in history]\n",
        "ax2.plot(losses, 'b-', linewidth=2)\n",
        "ax2.scatter(range(len(losses)), losses, color='blue', s=20)\n",
        "ax2.set_xlabel('Step')\n",
        "ax2.set_ylabel('Loss')\n",
        "ax2.set_title('Loss Over Training Steps', fontweight='bold')\n",
        "ax2.set_yscale('log')\n",
        "ax2.grid(True, alpha=0.3)\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üí° Key Insight: Gradient descent 'rolls downhill' on the loss surface!\")\n",
        "print(\"   Each step moves in the direction of steepest descent.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "4u7GcA81O0aO",
        "outputId": "ed18e06d-aa79-454c-cee4-3eb756dc0aa8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'plt' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2377736432.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Visualizing the gradient descent path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplots\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfigsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m14\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Left: Path on contour plot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0max1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'plt' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Gradient Descent Implementation\n",
        "def gradient_descent(loss_fn, grad_fn, initial_weights, learning_rate, num_steps):\n",
        "    \"\"\"\n",
        "    Perform gradient descent optimization.\n",
        "\n",
        "    Returns: history of (weights, loss) at each step\n",
        "    \"\"\"\n",
        "    weights = np.array(initial_weights, dtype=float)\n",
        "    history = [(weights.copy(), loss_fn(*weights))]\n",
        "\n",
        "    for _ in range(num_steps):\n",
        "        gradient = grad_fn(*weights)\n",
        "        weights = weights - learning_rate * gradient\n",
        "        history.append((weights.copy(), loss_fn(*weights)))\n",
        "\n",
        "    return history\n",
        "\n",
        "# Use our loss function from before\n",
        "# loss(w1, w2) = (w1 - 1)¬≤ + (w2 + 0.5)¬≤\n",
        "# Minimum at (1, -0.5)\n",
        "\n",
        "initial = [-1.5, 1.5]\n",
        "lr = 0.1\n",
        "steps = 30\n",
        "\n",
        "history = gradient_descent(loss, loss_gradient, initial, lr, steps)\n",
        "\n",
        "print(\"üöÄ Gradient Descent in Action\")\n",
        "print(\"=\"*50)\n",
        "print(f\"Loss function: L(w‚ÇÅ, w‚ÇÇ) = (w‚ÇÅ - 1)¬≤ + (w‚ÇÇ + 0.5)¬≤\")\n",
        "print(f\"True minimum: (1.0, -0.5)\")\n",
        "print(f\"Initial weights: {initial}\")\n",
        "print(f\"Learning rate: {lr}\")\n",
        "print(f\"\\nOptimization path:\")\n",
        "for i, (w, l) in enumerate(history[:6]):\n",
        "    print(f\"  Step {i}: w = [{w[0]:.4f}, {w[1]:.4f}], loss = {l:.4f}\")\n",
        "print(\"  ...\")\n",
        "final_w, final_l = history[-1]\n",
        "print(f\"  Step {len(history)-1}: w = [{final_w[0]:.4f}, {final_w[1]:.4f}], loss = {final_l:.6f}\")\n",
        "print(f\"\\n‚úÖ Converged to approximately (1.0, -0.5)!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 270
        },
        "id": "CTSRNZvqO0aO",
        "outputId": "2ab407b6-2f56-42d4-9cf5-098643acae79"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'loss' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2358214658.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0msteps\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m30\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mhistory\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgradient_descent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_gradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minitial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msteps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"üöÄ Gradient Descent in Action\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'loss' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4Ô∏è‚É£ Gradient Descent - How Neural Networks Learn\n",
        "\n",
        "**Gradient descent** is the algorithm that makes neural networks learn:\n",
        "\n",
        "```\n",
        "repeat:\n",
        "    gradient = compute_gradient(loss, weights)\n",
        "    weights = weights - learning_rate * gradient\n",
        "```\n",
        "\n",
        "The key equation:\n",
        "\n",
        "$$\\mathbf{w}_{new} = \\mathbf{w}_{old} - \\eta \\cdot \\nabla L$$\n",
        "\n",
        "Where:\n",
        "- **Œ∑** (eta) = learning rate (step size)\n",
        "- **‚àáL** = gradient of loss with respect to weights"
      ],
      "metadata": {
        "id": "g0D3T6B-O0aO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "‚úÖ **Section 3 Complete!** You now understand:\n",
        "- Partial derivatives for individual variables\n",
        "- Gradients as vectors of all partials\n",
        "- Gradient direction = steepest ascent\n",
        "\n",
        "Next: **Gradient Descent** - the learning algorithm!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "Y4ePU6LcO0aO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing gradient on a loss surface\n",
        "fig = plt.figure(figsize=(14, 5))\n",
        "\n",
        "# Loss function (bowl shape)\n",
        "def loss(w1, w2):\n",
        "    return (w1 - 1)**2 + (w2 + 0.5)**2\n",
        "\n",
        "def loss_gradient(w1, w2):\n",
        "    return np.array([2*(w1 - 1), 2*(w2 + 0.5)])\n",
        "\n",
        "# Create grid\n",
        "w1_range = np.linspace(-2, 4, 50)\n",
        "w2_range = np.linspace(-3, 2, 50)\n",
        "W1, W2 = np.meshgrid(w1_range, w2_range)\n",
        "L = loss(W1, W2)\n",
        "\n",
        "# 3D surface\n",
        "ax1 = fig.add_subplot(121, projection='3d')\n",
        "ax1.plot_surface(W1, W2, L, cmap='viridis', alpha=0.8)\n",
        "ax1.set_xlabel('w‚ÇÅ')\n",
        "ax1.set_ylabel('w‚ÇÇ')\n",
        "ax1.set_zlabel('Loss')\n",
        "ax1.set_title('Loss Surface\\n(Bowl-shaped)', fontweight='bold')\n",
        "\n",
        "# 2D contour with gradient arrows\n",
        "ax2 = fig.add_subplot(122)\n",
        "contour = ax2.contour(W1, W2, L, levels=15, cmap='viridis')\n",
        "ax2.clabel(contour, inline=True, fontsize=8)\n",
        "\n",
        "# Plot gradient arrows at several points\n",
        "points = [(-1, 1), (0, 0), (2, -1), (3, 1)]\n",
        "for w1, w2 in points:\n",
        "    grad = loss_gradient(w1, w2)\n",
        "    # Negative gradient (direction of descent)\n",
        "    ax2.arrow(w1, w2, -grad[0]*0.3, -grad[1]*0.3,\n",
        "              head_width=0.15, head_length=0.1, fc='red', ec='red')\n",
        "\n",
        "# Mark minimum\n",
        "ax2.scatter([1], [-0.5], color='green', s=200, marker='*', zorder=5, label='Minimum')\n",
        "ax2.set_xlabel('w‚ÇÅ')\n",
        "ax2.set_ylabel('w‚ÇÇ')\n",
        "ax2.set_title('Contour Plot with Negative Gradient\\n(Arrows point toward minimum)', fontweight='bold')\n",
        "ax2.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üí° Key Insight: Gradient descent follows the negative gradient downhill!\")\n",
        "print(\"   Red arrows show the direction we should move to reduce loss.\")"
      ],
      "metadata": {
        "id": "Dvtec7iTO0aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: f(x, y) = x¬≤ + 2xy + y¬≤\n",
        "def f(x, y):\n",
        "    return x**2 + 2*x*y + y**2\n",
        "\n",
        "# Partial derivatives (computed analytically)\n",
        "def df_dx(x, y):\n",
        "    \"\"\"‚àÇf/‚àÇx = 2x + 2y (treat y as constant)\"\"\"\n",
        "    return 2*x + 2*y\n",
        "\n",
        "def df_dy(x, y):\n",
        "    \"\"\"‚àÇf/‚àÇy = 2x + 2y (treat x as constant)\"\"\"\n",
        "    return 2*x + 2*y\n",
        "\n",
        "def gradient(x, y):\n",
        "    \"\"\"Gradient = [‚àÇf/‚àÇx, ‚àÇf/‚àÇy]\"\"\"\n",
        "    return np.array([df_dx(x, y), df_dy(x, y)])\n",
        "\n",
        "# Test at point (1, 2)\n",
        "x, y = 1.0, 2.0\n",
        "print(\"üìê Partial Derivatives and Gradient\")\n",
        "print(\"=\"*45)\n",
        "print(f\"Function: f(x, y) = x¬≤ + 2xy + y¬≤\")\n",
        "print(f\"Point: (x, y) = ({x}, {y})\")\n",
        "print(f\"f({x}, {y}) = {f(x, y)}\")\n",
        "print(f\"\\n‚àÇf/‚àÇx = 2x + 2y = {df_dx(x, y)}\")\n",
        "print(f\"‚àÇf/‚àÇy = 2x + 2y = {df_dy(x, y)}\")\n",
        "print(f\"\\nGradient ‚àáf = [{df_dx(x, y)}, {df_dy(x, y)}]\")\n",
        "print(f\"Gradient magnitude: {np.linalg.norm(gradient(x, y)):.2f}\")\n",
        "\n",
        "print(\"\\nüí° The gradient points toward steepest ascent!\")\n",
        "print(\"   To minimize, go in the OPPOSITE direction (negative gradient).\")"
      ],
      "metadata": {
        "id": "P26SV2n0O0aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3Ô∏è‚É£ Partial Derivatives & Gradients\n",
        "\n",
        "Neural networks have **millions of parameters**. We need derivatives with respect to EACH one!\n",
        "\n",
        "### Partial Derivative\n",
        "\n",
        "A **partial derivative** measures how a function changes with respect to ONE variable, treating others as constants.\n",
        "\n",
        "$$\\frac{\\partial f}{\\partial x} = \\text{derivative of } f \\text{ treating everything except } x \\text{ as constant}$$\n",
        "\n",
        "### Gradient\n",
        "\n",
        "The **gradient** is a vector of ALL partial derivatives:\n",
        "\n",
        "$$\\nabla f = \\begin{bmatrix} \\frac{\\partial f}{\\partial x_1} \\\\ \\frac{\\partial f}{\\partial x_2} \\\\ \\vdots \\\\ \\frac{\\partial f}{\\partial x_n} \\end{bmatrix}$$\n",
        "\n",
        "**Key property**: The gradient points in the direction of **steepest increase**!"
      ],
      "metadata": {
        "id": "CpAw-YCdO0aP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "‚úÖ **Section 2 Complete!** You now understand:\n",
        "- Chain rule for composed functions\n",
        "- How gradients flow backward through layers\n",
        "- The mathematical foundation of backpropagation\n",
        "\n",
        "Next: **Partial Derivatives & Gradients** - multiple variables!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "R31uuvGHO0aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Deep Learning Example: Chain Rule Through a Mini Network\n",
        "# x ‚Üí [w1] ‚Üí z1 ‚Üí [sigmoid] ‚Üí a1 ‚Üí [w2] ‚Üí z2 ‚Üí [MSE loss] ‚Üí L\n",
        "\n",
        "def forward_pass(x, w1, w2, y_true):\n",
        "    \"\"\"Forward pass through mini network\"\"\"\n",
        "    # Layer 1\n",
        "    z1 = w1 * x\n",
        "    a1 = 1 / (1 + np.exp(-z1))  # Sigmoid\n",
        "\n",
        "    # Layer 2\n",
        "    z2 = w2 * a1\n",
        "    prediction = z2\n",
        "\n",
        "    # Loss (MSE)\n",
        "    loss = (prediction - y_true) ** 2\n",
        "\n",
        "    return z1, a1, z2, prediction, loss\n",
        "\n",
        "def backward_pass(x, w1, w2, y_true, z1, a1, z2, prediction):\n",
        "    \"\"\"Backward pass using chain rule\"\"\"\n",
        "    # dL/d(prediction) = 2(prediction - y_true)\n",
        "    dL_dpred = 2 * (prediction - y_true)\n",
        "\n",
        "    # dL/dz2 = dL/dpred * dpred/dz2 = dL/dpred * 1\n",
        "    dL_dz2 = dL_dpred\n",
        "\n",
        "    # dL/dw2 = dL/dz2 * dz2/dw2 = dL/dz2 * a1\n",
        "    dL_dw2 = dL_dz2 * a1\n",
        "\n",
        "    # dL/da1 = dL/dz2 * dz2/da1 = dL/dz2 * w2\n",
        "    dL_da1 = dL_dz2 * w2\n",
        "\n",
        "    # dL/dz1 = dL/da1 * da1/dz1 = dL/da1 * sigmoid'(z1)\n",
        "    sigmoid_deriv = a1 * (1 - a1)  # Sigmoid derivative\n",
        "    dL_dz1 = dL_da1 * sigmoid_deriv\n",
        "\n",
        "    # dL/dw1 = dL/dz1 * dz1/dw1 = dL/dz1 * x\n",
        "    dL_dw1 = dL_dz1 * x\n",
        "\n",
        "    return dL_dw1, dL_dw2\n",
        "\n",
        "# Test\n",
        "x = 2.0\n",
        "w1 = 0.5\n",
        "w2 = 0.8\n",
        "y_true = 1.0\n",
        "\n",
        "z1, a1, z2, pred, loss = forward_pass(x, w1, w2, y_true)\n",
        "dL_dw1, dL_dw2 = backward_pass(x, w1, w2, y_true, z1, a1, z2, pred)\n",
        "\n",
        "print(\"üß† Chain Rule Through a Neural Network\")\n",
        "print(\"=\"*50)\n",
        "print(\"Network: x ‚Üí w1 ‚Üí sigmoid ‚Üí w2 ‚Üí MSE Loss\")\n",
        "print(f\"\\nForward Pass:\")\n",
        "print(f\"  x = {x}\")\n",
        "print(f\"  z1 = w1 √ó x = {w1} √ó {x} = {z1}\")\n",
        "print(f\"  a1 = sigmoid(z1) = {a1:.4f}\")\n",
        "print(f\"  z2 = w2 √ó a1 = {w2} √ó {a1:.4f} = {z2:.4f}\")\n",
        "print(f\"  prediction = {pred:.4f}\")\n",
        "print(f\"  loss = (pred - y)¬≤ = ({pred:.4f} - {y_true})¬≤ = {loss:.4f}\")\n",
        "\n",
        "print(f\"\\nBackward Pass (Chain Rule!):\")\n",
        "print(f\"  dL/dw2 = {dL_dw2:.4f}\")\n",
        "print(f\"  dL/dw1 = {dL_dw1:.4f}\")\n",
        "\n",
        "print(\"\\nüí° These gradients tell us how to adjust w1 and w2 to reduce loss!\")"
      ],
      "metadata": {
        "id": "fCo0lw2QO0aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Chain Rule Example: y = (3x + 2)¬≤\n",
        "# Let g(x) = 3x + 2, and y = g¬≤\n",
        "# dy/dx = dy/dg * dg/dx = 2g * 3 = 6(3x + 2)\n",
        "\n",
        "def g(x):\n",
        "    return 3 * x + 2\n",
        "\n",
        "def y(x):\n",
        "    return g(x) ** 2\n",
        "\n",
        "# Derivatives\n",
        "def dg_dx(x):\n",
        "    return 3  # d/dx(3x + 2) = 3\n",
        "\n",
        "def dy_dg(x):\n",
        "    return 2 * g(x)  # d/dg(g¬≤) = 2g\n",
        "\n",
        "def dy_dx_chain_rule(x):\n",
        "    return dy_dg(x) * dg_dx(x)  # Chain rule!\n",
        "\n",
        "x_test = 2.0\n",
        "print(\"‚õìÔ∏è Chain Rule Example: y = (3x + 2)¬≤\")\n",
        "print(\"=\"*45)\n",
        "print(f\"x = {x_test}\")\n",
        "print(f\"g(x) = 3x + 2 = {g(x_test)}\")\n",
        "print(f\"y = g¬≤ = {y(x_test)}\")\n",
        "print(f\"\\nUsing Chain Rule:\")\n",
        "print(f\"  dg/dx = 3\")\n",
        "print(f\"  dy/dg = 2g = 2 √ó {g(x_test)} = {dy_dg(x_test)}\")\n",
        "print(f\"  dy/dx = dy/dg √ó dg/dx = {dy_dg(x_test)} √ó {dg_dx(x_test)} = {dy_dx_chain_rule(x_test)}\")\n",
        "print(f\"\\nVerify numerically: {numerical_derivative(y, x_test):.4f}\")\n",
        "print(f\"‚úÖ Match!\")"
      ],
      "metadata": {
        "id": "trpoRJH8O0aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2Ô∏è‚É£ The Chain Rule - Heart of Backpropagation\n",
        "\n",
        "The **chain rule** tells us how to take derivatives of composed functions.\n",
        "\n",
        "If `y = f(g(x))`, then:\n",
        "\n",
        "$$\\frac{dy}{dx} = \\frac{dy}{dg} \\cdot \\frac{dg}{dx}$$\n",
        "\n",
        "**This is EXACTLY how backpropagation works!** Gradients flow backward through each layer.\n",
        "\n",
        "```\n",
        "Input ‚Üí Layer 1 ‚Üí Layer 2 ‚Üí Layer 3 ‚Üí Loss\n",
        "         ‚Üë          ‚Üë          ‚Üë\n",
        "         ‚îÇ          ‚îÇ          ‚îÇ\n",
        "    ‚Üê dL/dW1 ‚Üê dL/dW2 ‚Üê dL/dW3 ‚Üê\n",
        "    \n",
        "    (Chain rule multiplies gradients backward!)\n",
        "```"
      ],
      "metadata": {
        "id": "nP5y9LIuO0aP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n",
        "\n",
        "‚úÖ **Section 1 Complete!** You now understand:\n",
        "- Derivatives measure rate of change\n",
        "- Numerical vs analytical computation\n",
        "- Why ReLU helps with vanishing gradients\n",
        "\n",
        "Next: **Chain Rule** - the backbone of backpropagation!\n",
        "\n",
        "---"
      ],
      "metadata": {
        "id": "lznBHme1O0aP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualizing activation functions and their derivatives\n",
        "fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
        "\n",
        "x = np.linspace(-5, 5, 200)\n",
        "\n",
        "# Sigmoid\n",
        "sigmoid = 1 / (1 + np.exp(-x))\n",
        "sigmoid_deriv = sigmoid * (1 - sigmoid)\n",
        "axes[0, 0].plot(x, sigmoid, 'b-', linewidth=2, label='œÉ(x)')\n",
        "axes[0, 0].set_title('Sigmoid', fontweight='bold')\n",
        "axes[1, 0].plot(x, sigmoid_deriv, 'r-', linewidth=2, label=\"œÉ'(x)\")\n",
        "axes[1, 0].set_title(\"Sigmoid Derivative\", fontweight='bold')\n",
        "\n",
        "# Tanh\n",
        "tanh = np.tanh(x)\n",
        "tanh_deriv = 1 - tanh**2\n",
        "axes[0, 1].plot(x, tanh, 'b-', linewidth=2, label='tanh(x)')\n",
        "axes[0, 1].set_title('Tanh', fontweight='bold')\n",
        "axes[1, 1].plot(x, tanh_deriv, 'r-', linewidth=2, label=\"tanh'(x)\")\n",
        "axes[1, 1].set_title(\"Tanh Derivative\", fontweight='bold')\n",
        "\n",
        "# ReLU\n",
        "relu = np.maximum(0, x)\n",
        "relu_deriv = (x > 0).astype(float)\n",
        "axes[0, 2].plot(x, relu, 'b-', linewidth=2, label='ReLU(x)')\n",
        "axes[0, 2].set_title('ReLU', fontweight='bold')\n",
        "axes[1, 2].plot(x, relu_deriv, 'r-', linewidth=2, label=\"ReLU'(x)\")\n",
        "axes[1, 2].set_title(\"ReLU Derivative\", fontweight='bold')\n",
        "\n",
        "for ax in axes.flat:\n",
        "    ax.axhline(y=0, color='k', linewidth=0.5)\n",
        "    ax.axvline(x=0, color='k', linewidth=0.5)\n",
        "    ax.grid(True, alpha=0.3)\n",
        "    ax.legend()\n",
        "    ax.set_xlabel('x')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "print(\"üí° Key Insights:\")\n",
        "print(\"   ‚Ä¢ Sigmoid/Tanh: Derivatives ‚Üí 0 for large |x| (vanishing gradient problem!)\")\n",
        "print(\"   ‚Ä¢ ReLU: Derivative is 0 or 1 (no vanishing gradient for x > 0)\")\n",
        "print(\"   ‚Ä¢ This is why ReLU became the default activation in modern networks!\")"
      ],
      "metadata": {
        "id": "YuU2KZprO0aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Computing derivatives numerically vs analytically\n",
        "def numerical_derivative(f, x, h=1e-5):\n",
        "    \"\"\"Compute derivative using finite differences\"\"\"\n",
        "    return (f(x + h) - f(x - h)) / (2 * h)  # Central difference (more accurate)\n",
        "\n",
        "# Example: f(x) = x¬≤\n",
        "def f(x):\n",
        "    return x ** 2\n",
        "\n",
        "def f_derivative_analytical(x):\n",
        "    \"\"\"Analytical derivative: d/dx(x¬≤) = 2x\"\"\"\n",
        "    return 2 * x\n",
        "\n",
        "x_test = 3.0\n",
        "numerical = numerical_derivative(f, x_test)\n",
        "analytical = f_derivative_analytical(x_test)\n",
        "\n",
        "print(\"üìê Computing Derivatives\")\n",
        "print(\"=\"*40)\n",
        "print(f\"Function: f(x) = x¬≤\")\n",
        "print(f\"At x = {x_test}:\")\n",
        "print(f\"  f({x_test}) = {f(x_test)}\")\n",
        "print(f\"\\n  Numerical derivative:  {numerical:.6f}\")\n",
        "print(f\"  Analytical derivative: {analytical:.6f}\")\n",
        "print(f\"  Difference: {abs(numerical - analytical):.10f}\")\n",
        "print(\"\\n‚úÖ They match! (tiny error is from numerical approximation)\")"
      ],
      "metadata": {
        "id": "SIxJJqwVO0aP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wxP51pVdO0aP"
      },
      "source": [
        "# üìà Calculus for Deep Learning\n",
        "\n",
        "## A Beginner-Friendly, Zero-to-Hero Guide\n",
        "\n",
        "---\n",
        "\n",
        "**Welcome!** This notebook will teach you the essential calculus concepts that make neural networks learn. While linear algebra defines *what* computations happen, calculus tells us *how to improve* our model.\n",
        "\n",
        "### üéØ What You'll Learn\n",
        "\n",
        "| Section | Topic | Deep Learning Connection |\n",
        "|---------|-------|-------------------------|\n",
        "| 1 | Derivatives | Rate of change, sensitivity |\n",
        "| 2 | Chain Rule | Backpropagation foundation |\n",
        "| 3 | Partial Derivatives & Gradients | Multi-variable optimization |\n",
        "| 4 | Gradient Descent | How neural networks learn |\n",
        "| 5 | Backpropagation | The heart of deep learning |\n",
        "\n",
        "### üß† Why Calculus Matters for Deep Learning\n",
        "\n",
        "```\n",
        "Training Loop:\n",
        "1. Forward pass    ‚Üí Compute predictions\n",
        "2. Compute loss    ‚Üí How wrong are we?\n",
        "3. BACKPROPAGATION ‚Üí Use CALCULUS to find gradients\n",
        "4. Update weights  ‚Üí Move in opposite direction of gradient\n",
        "5. Repeat!\n",
        "```\n",
        "\n",
        "**Neural networks learn by computing derivatives and following gradients downhill!**\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U5sDQcTqO0aP"
      },
      "source": [
        "## ‚öôÔ∏è Setup\n",
        "\n",
        "Let's import the libraries we'll use throughout this notebook."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5Vz1VnDO0aP"
      },
      "source": [
        "# Core libraries\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from mpl_toolkits.mplot3d import Axes3D\n",
        "\n",
        "# For beautiful visualizations\n",
        "plt.style.use('seaborn-v0_8-whitegrid')\n",
        "plt.rcParams['figure.figsize'] = [10, 6]\n",
        "plt.rcParams['font.size'] = 12\n",
        "\n",
        "# Set random seed for reproducibility\n",
        "np.random.seed(42)\n",
        "\n",
        "print(\"‚úÖ Setup complete!\")\n",
        "print(f\"NumPy version: {np.__version__}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7IBhnUkO0aP"
      },
      "source": [
        "## üìö Introduction: The Language of Learning\n",
        "\n",
        "Before diving into derivatives, let's understand the big picture.\n",
        "\n",
        "### The Learning Problem\n",
        "\n",
        "Neural networks have **millions of parameters** (weights and biases). How do we know which direction to adjust them to make better predictions?\n",
        "\n",
        "**Answer: Derivatives!**\n",
        "\n",
        "A derivative tells us:\n",
        "- **Direction**: Should we increase or decrease a weight?\n",
        "- **Magnitude**: How sensitive is the output to this weight?\n",
        "\n",
        "Let's see a simple example:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J7IIeCZDO0aP"
      },
      "source": [
        "# Simple example: How does changing weight affect output?\n",
        "\n",
        "def simple_neuron(x, w):\n",
        "    \"\"\"A single neuron: output = w * x\"\"\"\n",
        "    return w * x\n",
        "\n",
        "x = 2.0  # Fixed input\n",
        "weights = np.linspace(-2, 2, 100)\n",
        "outputs = [simple_neuron(x, w) for w in weights]\n",
        "\n",
        "# Plot\n",
        "plt.figure(figsize=(10, 5))\n",
        "plt.plot(weights, outputs, 'b-', linewidth=2)\n",
        "plt.axhline(y=0, color='k', linewidth=0.5)\n",
        "plt.axvline(x=0, color='k', linewidth=0.5)\n",
        "\n",
        "# Mark current weight and show slope\n",
        "w_current = 1.0\n",
        "y_current = simple_neuron(x, w_current)\n",
        "plt.scatter([w_current], [y_current], color='red', s=100, zorder=5)\n",
        "plt.annotate(f'Current: w={w_current}, output={y_current}',\n",
        "             xy=(w_current, y_current), xytext=(w_current+0.5, y_current+1),\n",
        "             fontsize=11, arrowprops=dict(arrowstyle='->', color='red'))\n",
        "\n",
        "# Draw tangent line (the derivative!)\n",
        "slope = x  # dy/dw = x (the derivative)\n",
        "tangent_x = np.array([w_current-0.5, w_current+0.5])\n",
        "tangent_y = y_current + slope * (tangent_x - w_current)\n",
        "plt.plot(tangent_x, tangent_y, 'r--', linewidth=2, label=f'Slope = {slope} (derivative)')\n",
        "\n",
        "plt.xlabel('Weight (w)', fontsize=12)\n",
        "plt.ylabel('Output (w √ó x)', fontsize=12)\n",
        "plt.title('How Output Changes with Weight\\n(The slope IS the derivative!)', fontsize=14, fontweight='bold')\n",
        "plt.legend()\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.show()\n",
        "\n",
        "print(\"üí° Key Insight:\")\n",
        "print(f\"   If we increase w by a tiny amount Œµ, output increases by {x}Œµ\")\n",
        "print(f\"   The derivative dy/dw = {x} tells us exactly this rate of change!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzvp70oKO0aQ"
      },
      "source": [
        "---\n",
        "\n",
        "### üéì What's Next?\n",
        "\n",
        "Now that you've seen the intuition, we'll systematically build up:\n",
        "\n",
        "1. **Derivatives** - The fundamental concept\n",
        "2. **Chain Rule** - Derivatives of composed functions\n",
        "3. **Gradients** - Derivatives with multiple variables\n",
        "4. **Gradient Descent** - Using derivatives to learn\n",
        "5. **Backpropagation** - Efficient gradient computation\n",
        "\n",
        "Let's begin! üöÄ\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1Ô∏è‚É£ Derivatives: The Foundation\n",
        "\n",
        "A **derivative** measures how much a function's output changes when its input changes by a tiny amount.\n",
        "\n",
        "$$\\frac{df}{dx} = \\lim_{h \\to 0} \\frac{f(x + h) - f(x)}{h}$$\n",
        "\n",
        "### Common Derivatives in Deep Learning\n",
        "\n",
        "| Function | Derivative | Deep Learning Use |\n",
        "|----------|------------|-------------------|\n",
        "| f(x) = x¬≤ | f'(x) = 2x | MSE loss |\n",
        "| f(x) = eÀ£ | f'(x) = eÀ£ | Softmax |\n",
        "| f(x) = ln(x) | f'(x) = 1/x | Cross-entropy loss |\n",
        "| f(x) = sigmoid | f'(x) = f(x)(1-f(x)) | Activation |\n",
        "| f(x) = ReLU | f'(x) = 0 or 1 | Activation |"
      ],
      "metadata": {
        "id": "7TnKT4mjO0aQ"
      }
    }
  ]
}